{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "u9lHfIZ-yRVo"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, classification_report\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qOAnXXaKyhZH",
        "outputId": "9abb78cf-b65b-4fe6-8a6b-be1285b47486"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_labels(file_path):\n",
        "    \"\"\"Load labels from an Excel file.\"\"\"\n",
        "    try:\n",
        "        df = pd.read_excel(file_path)\n",
        "        print(\"Dataset Loaded Successfully!\")\n",
        "        print(df.head())\n",
        "        return df\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: File not found at {file_path}\")\n",
        "        return None\n",
        "\n",
        "# Load dataset\n",
        "labels_df = load_labels(\"/mnt/data/labels..xlsx\")\n",
        "if labels_df is None:\n",
        "    raise FileNotFoundError(\"Labels file is missing! Check file path.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2KI2E-wzD90",
        "outputId": "34859986-bbc8-479f-f87a-7afa854e2ba9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Loaded Successfully!\n",
            "   Unnamed: 0.2  Unnamed: 0.1  Unnamed: 0      family          genus  \\\n",
            "0             0         68711       70465   Veneridae  Hysteroconcha   \n",
            "1             1          6018        6162   Cardiidae   Acrosterigma   \n",
            "2             2         42500       44103  Pectinidae   Decatopecten   \n",
            "3             3         32647       34008   Mytilidae   Brachidontes   \n",
            "4             4         11386       11538  Carditidae        Cardita   \n",
            "\n",
            "                  species                                           filename  \\\n",
            "0  Hysteroconchalupanaria  Veneridae_Hysteroconcha_lupanaria_allspira_26-...   \n",
            "1  Acrosterigmaattenuatum    Cardiidae_Acrosterigma_attenuatum_bigai_010.jpg   \n",
            "2    Decatopectenamiculum  Pectinidae_Decatopecten_amiculum_Poppe_263539-...   \n",
            "3  Brachidontessemilaevis  Mytilidae_Brachidontes_semilaevis_Poppe_284926...   \n",
            "4     Carditaplanicostata  Carditidae_Cardita_planicostata_PRI_132-view2-...   \n",
            "\n",
            "  ansicht      order          subclass  ... family_idx  genus_idx  \\\n",
            "0  aussen   Venerida      Imparidentia  ...         47        410   \n",
            "1  aussen   Cardiida      Imparidentia  ...         55          8   \n",
            "2  aussen  Pectinida     Pteriomorphia  ...         23        258   \n",
            "3  aussen   Mytilida     Pteriomorphia  ...         12        122   \n",
            "4   innen  Carditida  Archiheterodonta  ...         73        143   \n",
            "\n",
            "   species_idx  ansicht_idx  order_idx  subclass_idx  Index  \\\n",
            "0         1841            0         26             2  70465   \n",
            "1           74            0          2             2   6162   \n",
            "2         1184            0         20             5  44103   \n",
            "3          592            0         15             5  34008   \n",
            "4          702            1          3             1  11538   \n",
            "\n",
            "                                            FilePath ClassNo  FileType  \n",
            "0  IMAGES_final/Veneridae_Hysteroconcha_lupanaria...    1841     image  \n",
            "1  IMAGES_final/Cardiidae_Acrosterigma_attenuatum...      74     image  \n",
            "2  IMAGES_final/Pectinidae_Decatopecten_amiculum_...    1184     image  \n",
            "3  IMAGES_final/Mytilidae_Brachidontes_semilaevis...     592     image  \n",
            "4  IMAGES_final/Carditidae_Cardita_planicostata_P...     702     image  \n",
            "\n",
            "[5 rows x 21 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def find_rare_classes(df, level, threshold=10):\n",
        "    \"\"\"Find rare classes in a given taxonomic level.\"\"\"\n",
        "    class_counts = df[level].value_counts()\n",
        "    rare_classes = class_counts[class_counts < threshold].index\n",
        "    return list(rare_classes)\n",
        "\n",
        "# Identify rare classes\n",
        "rare_classes = {level: find_rare_classes(labels_df, level) for level in [\"family\", \"order\", \"subclass\"]}\n",
        "print(\"Rare classes:\", rare_classes)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1L2bwVd8zRgz",
        "outputId": "fbfcf685-f40e-4c9a-aeaa-0d8e8db028b9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rare classes: {'family': ['Cyamiidae', 'Cleidothaeridae'], 'order': ['Cyamioidea'], 'subclass': []}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the number of samples for each family\n",
        "family_counts = labels_df['family'].value_counts()\n",
        "print(\"\\nNumber of samples for each family:\")\n",
        "for family, count in family_counts.items():\n",
        "    print(f\"Family: {family}, Count: {count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WznUNJgtZpMa",
        "outputId": "991b1a10-b7db-4dd6-bc1b-6f165d83f22d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Number of samples for each family:\n",
            "Family: Pectinidae, Count: 9293\n",
            "Family: Cardiidae, Count: 5390\n",
            "Family: Tellinidae, Count: 5330\n",
            "Family: Veneridae, Count: 4725\n",
            "Family: Mytilidae, Count: 4141\n",
            "Family: Arcidae, Count: 4038\n",
            "Family: Lucinidae, Count: 3140\n",
            "Family: Mactridae, Count: 2408\n",
            "Family: Spondylidae, Count: 2033\n",
            "Family: Glycymerididae, Count: 1999\n",
            "Family: Carditidae, Count: 1707\n",
            "Family: Limidae, Count: 1552\n",
            "Family: Donacidae, Count: 1518\n",
            "Family: Psammobiidae, Count: 1459\n",
            "Family: Nuculanidae, Count: 1164\n",
            "Family: Semelidae, Count: 1136\n",
            "Family: Ostreidae, Count: 1117\n",
            "Family: Nuculidae, Count: 1055\n",
            "Family: Cuspidariidae, Count: 978\n",
            "Family: Corbulidae, Count: 946\n",
            "Family: Lasaeidae, Count: 944\n",
            "Family: Propeamussiidae, Count: 931\n",
            "Family: Chamidae, Count: 834\n",
            "Family: Pinnidae, Count: 824\n",
            "Family: Pharidae, Count: 799\n",
            "Family: Anomiidae, Count: 761\n",
            "Family: Pholadidae, Count: 757\n",
            "Family: Astartidae, Count: 665\n",
            "Family: Yoldiidae, Count: 663\n",
            "Family: Crassatellidae, Count: 573\n",
            "Family: Glossidae, Count: 508\n",
            "Family: Pteriidae, Count: 472\n",
            "Family: Isognomonidae, Count: 470\n",
            "Family: Thyasiridae, Count: 465\n",
            "Family: Noetiidae, Count: 443\n",
            "Family: Ungulinidae, Count: 431\n",
            "Family: Solecurtidae, Count: 404\n",
            "Family: Solenidae, Count: 403\n",
            "Family: Thraciidae, Count: 387\n",
            "Family: Hiatellidae, Count: 375\n",
            "Family: Myidae, Count: 368\n",
            "Family: Limopsidae, Count: 346\n",
            "Family: Pandoridae, Count: 323\n",
            "Family: Cyrenidae, Count: 306\n",
            "Family: Plicatulidae, Count: 280\n",
            "Family: Lyonsiidae, Count: 203\n",
            "Family: Galeommatidae, Count: 200\n",
            "Family: Vesicomyidae, Count: 199\n",
            "Family: Malleidae, Count: 198\n",
            "Family: Laternulidae, Count: 193\n",
            "Family: Gryphaeidae, Count: 190\n",
            "Family: Malletiidae, Count: 169\n",
            "Family: Poromyidae, Count: 163\n",
            "Family: Solemyidae, Count: 161\n",
            "Family: Trapezidae, Count: 161\n",
            "Family: Periplomatidae, Count: 149\n",
            "Family: Dreissenidae, Count: 132\n",
            "Family: Myochamidae, Count: 120\n",
            "Family: Gaimardiidae, Count: 110\n",
            "Family: Verticordiidae, Count: 87\n",
            "Family: Glauconomidae, Count: 86\n",
            "Family: Teredinidae, Count: 72\n",
            "Family: Gastrochaenidae, Count: 71\n",
            "Family: Arcticidae, Count: 69\n",
            "Family: Trigoniidae, Count: 67\n",
            "Family: Nucinellidae, Count: 61\n",
            "Family: Kelliellidae, Count: 38\n",
            "Family: Hemidonacidae, Count: 37\n",
            "Family: Placunidae, Count: 26\n",
            "Family: Cyrenoididae, Count: 24\n",
            "Family: Dimyidae, Count: 20\n",
            "Family: Pulvinitidae, Count: 11\n",
            "Family: Cyamiidae, Count: 7\n",
            "Family: Cleidothaeridae, Count: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the number of samples for each family\n",
        "order_counts = labels_df['order'].value_counts()\n",
        "print(\"\\nNumber of samples for each order:\")\n",
        "for order, count in order_counts.items():\n",
        "    print(f\"Order: {order}, Count: {count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CkjNJq0IZp8U",
        "outputId": "175419a4-2c9f-4704-bc8b-1937e8d80d21"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Number of samples for each order:\n",
            "Order: Cardiida, Count: 15237\n",
            "Order: Pectinida, Count: 13344\n",
            "Order: Venerida, Count: 9826\n",
            "Order: Arcida, Count: 6826\n",
            "Order: Mytilida, Count: 4141\n",
            "Order: Lucinida, Count: 3605\n",
            "Order: Ostreida, Count: 3282\n",
            "Order: Carditida, Count: 2945\n",
            "Order: Myida, Count: 2275\n",
            "Order: Nuculanida, Count: 1996\n",
            "Order: Adapedonta, Count: 1577\n",
            "Order: Limida, Count: 1552\n",
            "Order: Galeommatida, Count: 1144\n",
            "Order: Nuculida, Count: 1055\n",
            "Order: Cuspidarioidea, Count: 978\n",
            "Order: Thracioidea, Count: 536\n",
            "Order: Pandoroidea, Count: 526\n",
            "Order: Solemyida, Count: 222\n",
            "Order: Laternuloidea, Count: 193\n",
            "Order: Poromyoidea, Count: 163\n",
            "Order: Myochamoidea, Count: 123\n",
            "Order: Gaimardioidea, Count: 110\n",
            "Order: Verticordioidea, Count: 87\n",
            "Order: Gastrochaenida, Count: 71\n",
            "Order: Trigoniida, Count: 67\n",
            "Order: Cyamioidea, Count: 7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the number of samples for each family\n",
        "subclass_counts = labels_df['subclass'].value_counts()\n",
        "print(\"\\nNumber of samples for each subclass:\")\n",
        "for subclass, count in subclass_counts.items():\n",
        "    print(f\"Subclass: {subclass}, Count: {count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hN8GHU6_Zt3f",
        "outputId": "8c49b0bd-c85a-4fb9-fd54-f726f91c1224"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Number of samples for each subclass:\n",
            "Subclass: Imparidentia, Count: 33852\n",
            "Subclass: Pteriomorphia, Count: 29145\n",
            "Subclass: Protobranchia, Count: 3273\n",
            "Subclass: Archiheterodonta, Count: 2945\n",
            "Subclass: Anomalodesmata, Count: 2606\n",
            "Subclass: Paleoheterodonta, Count: 67\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_augmentation_model(shape=(224, 224, 3)):\n",
        "\n",
        "\n",
        "\n",
        "    augmentation_model = tf.keras.Sequential([\n",
        "        tf.keras.layers.InputLayer(shape=shape),\n",
        "        tf.keras.layers.RandomFlip(\"horizontal_and_vertical\"),\n",
        "        tf.keras.layers.RandomRotation(0.2),\n",
        "        tf.keras.layers.RandomZoom(0.2),\n",
        "        tf.keras.layers.RandomBrightness(0.1, value_range=[0, 255]),\n",
        "        tf.keras.layers.RandomContrast(0.2),\n",
        "        tf.keras.layers.GaussianNoise(0.02),\n",
        "        tf.keras.layers.RandomTranslation(0.1, 0.1),\n",
        "        tf.keras.layers.RandomCrop(height=shape[0], width=shape[1]),\n",
        "        tf.keras.layers.Lambda(lambda x: x, output_shape=shape)\n",
        "    ])\n",
        "    return augmentation_model\n"
      ],
      "metadata": {
        "id": "GpE0onAJ22Xn"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "augmentation_model = build_augmentation_model(shape=(224, 224, 3))"
      ],
      "metadata": {
        "id": "ackwu57FGdZB"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SIZE = (224, 224)\n",
        "\n",
        "def augment_image(image_path, augmentation_model):\n",
        "    \"\"\"Apply augmentation to an image.\"\"\"\n",
        "\n",
        "\n",
        "    img = cv2.imread(image_path)\n",
        "    img = cv2.resize(img, IMG_SIZE)\n",
        "    img = tf.convert_to_tensor(img, dtype=tf.float32)\n",
        "\n",
        "    img = augmentation_model(tf.expand_dims(img, axis=0))\n",
        "\n",
        "    return tf.squeeze(img).numpy()\n",
        "\n",
        "def augment_dataset(df, image_dir, augmentation_model, target_samples=5):\n",
        "    \"\"\"Augment images for rare classes.\"\"\"\n",
        "    augmented_samples = []\n",
        "\n",
        "    for level in [\"subclass\"]:\n",
        "        for cls in find_rare_classes(df, level):\n",
        "            class_samples = df[df[level] == cls]\n",
        "            num_samples = len(class_samples)\n",
        "\n",
        "            for i in range(target_samples - num_samples):\n",
        "                sample = class_samples.sample(1).iloc[0]\n",
        "                img_path = os.path.join(image_dir, sample[\"filename\"])\n",
        "\n",
        "                aug_img = augment_image(img_path, augmentation_model)\n",
        "                if aug_img is not None:\n",
        "                    aug_filename = f\"aug_{i}_{sample['filename']}\"\n",
        "                    aug_path = os.path.join(image_dir, aug_filename)\n",
        "                    cv2.imwrite(aug_path, cv2.cvtColor(aug_img, cv2.COLOR_RGB2BGR))\n",
        "\n",
        "                    new_sample = sample.copy()\n",
        "                    new_sample[\"filename\"] = aug_filename\n",
        "                    augmented_samples.append(new_sample)\n",
        "\n",
        "    return pd.concat([df, pd.DataFrame(augmented_samples)], ignore_index=True)\n",
        "\n",
        "\n",
        "labels_df = augment_dataset(labels_df, \"/content/drive/MyDrive/IMAGES_final\", augmentation_model)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "T_y0ilyTzVg9"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_dataset(df):\n",
        "    \"\"\"Split dataset into train and test sets.\"\"\"\n",
        "    train_test_sets = {}\n",
        "\n",
        "    for level in [\"subclass\"]:\n",
        "        train, test = train_test_split(df, test_size=0.2, stratify=df[level], random_state=42)\n",
        "        train_test_sets[level] = (train, test)\n",
        "\n",
        "    return train_test_sets\n",
        "\n",
        "data_splits = split_dataset(labels_df)\n",
        "\n"
      ],
      "metadata": {
        "id": "ksgeV-GR0ERL"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_labels(df, level):\n",
        "    \"\"\"Encode categorical labels into numerical values.\"\"\"\n",
        "    df = df.copy()  # Prevent modifying the original DataFrame\n",
        "    encoder = LabelEncoder()\n",
        "    df[level] = encoder.fit_transform(df[level])  # Transform labels\n",
        "    return df, encoder  # Return both the updated DataFrame & encoder\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "mO3vSIti3Ey1"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def add_gaussian_noise(image, stddev=10.0):  # Adjust stddev for [0,255] scale\n",
        "    \"\"\"Adds Gaussian noise to the image while keeping values in [0,255].\"\"\"\n",
        "    stddev = tf.cast(stddev, tf.float32)  # Ensure dtype compatibility\n",
        "    noise = tf.random.normal(shape=tf.shape(image), mean=0.0, stddev=stddev, dtype=image.dtype)\n",
        "    image = tf.clip_by_value(image + noise, 0.0, 255.0)  # ✅ Keep values in [0,255]\n",
        "    return image\n",
        "\n",
        "\n",
        "def augment_rare_samples(df, level, target_samples=1000, stddev=10):\n",
        "    \"\"\"\n",
        "    Augments rare class samples using Gaussian noise until each class reaches 1000 samples.\n",
        "    \"\"\"\n",
        "    df_encoded, encoder = encode_labels(df, level)\n",
        "\n",
        "    # Count occurrences of each class\n",
        "    class_counts = df_encoded[level].value_counts()\n",
        "    rare_classes = class_counts[class_counts < target_samples].index.tolist()\n",
        "\n",
        "    augmented_samples = []  # ✅ Store new augmented samples\n",
        "\n",
        "    for rare_class in rare_classes:\n",
        "        rare_class_samples = df_encoded[df_encoded[level] == rare_class]\n",
        "        num_existing = len(rare_class_samples)\n",
        "        num_needed = target_samples - num_existing  # ✅ How many more samples are needed?\n",
        "\n",
        "        # ✅ Sample images from the rare class (with replacement)\n",
        "        sampled_images = rare_class_samples.sample(num_needed, replace=True)\n",
        "\n",
        "        for _, row in sampled_images.iterrows():\n",
        "            augmented_samples.append({\n",
        "                \"filename\": row[\"filename\"],  # ✅ Uses original filename\n",
        "                level: rare_class,  # ✅ Maintains class label\n",
        "            })\n",
        "\n",
        "    # ✅ Convert augmented samples to DataFrame\n",
        "    df_augmented = pd.DataFrame(augmented_samples)\n",
        "\n",
        "    # ✅ Merge with original dataset\n",
        "    df_final = pd.concat([df_encoded, df_augmented], ignore_index=True)\n",
        "\n",
        "    return df_final\n",
        "\n",
        "def create_stratified_dataset(df, image_dir, level, batch_size=128, stddev=10.0):\n",
        "    \"\"\"\n",
        "    Creates a tf.data.Dataset where each batch contains samples from all 74 classes.\n",
        "    \"\"\"\n",
        "    df_balanced = augment_rare_samples(df, level, stddev=stddev)  # ✅ Use the fixed stddev\n",
        "\n",
        "    filepaths = df_balanced[\"filename\"].apply(lambda x: os.path.join(image_dir, x))\n",
        "    labels = df_balanced[level].values.astype(np.int64)  # ✅ Ensure correct dtype\n",
        "\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((filepaths, labels))\n",
        "\n",
        "    # ✅ Define preprocessing function inside create_stratified_dataset()\n",
        "    def load_and_preprocess(filepath, label):\n",
        "        \"\"\"Loads, preprocesses, and applies noise conditionally.\"\"\"\n",
        "        image = tf.io.read_file(filepath)\n",
        "        image = tf.image.decode_jpeg(image, channels=3)\n",
        "        image = tf.image.resize(image, (224, 224))  # ✅ Resizing added\n",
        "        image = tf.cast(image, tf.float32)\n",
        "\n",
        "        # ✅ Apply noise augmentation only to duplicated samples\n",
        "        image = tf.cond(\n",
        "            tf.equal(tf.reduce_sum(tf.where(labels == label)), 0),  # Check if it's an augmented sample\n",
        "            lambda: add_gaussian_noise(image, stddev),  # ✅ Apply Gaussian noise\n",
        "            lambda: image  # ✅ Keep original images unchanged\n",
        "        )\n",
        "        return image, label\n",
        "\n",
        "    dataset = dataset.map(load_and_preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "    # ** Create a separate dataset for each class **\n",
        "    class_datasets = []\n",
        "    unique_classes = np.unique(labels)\n",
        "\n",
        "    for class_label in unique_classes:\n",
        "        class_subset = dataset.filter(lambda x, y: tf.equal(y, class_label))\n",
        "        class_datasets.append(class_subset)\n",
        "\n",
        "    # ** Ensure each batch contains at least one sample from each class **\n",
        "    stratified_dataset = tf.data.Dataset.sample_from_datasets(\n",
        "        class_datasets, weights=[1/len(unique_classes)]*len(unique_classes)\n",
        "    )\n",
        "\n",
        "    # ✅ **Batch AFTER applying augmentation**\n",
        "    stratified_dataset = stratified_dataset.batch(batch_size, drop_remainder=True).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "    return stratified_dataset\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gceZENrAwSxw"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_image(image_path):\n",
        "    \"\"\"Load and preprocess an image.\"\"\"\n",
        "    image = tf.io.read_file(image_path)\n",
        "    image = tf.image.decode_jpeg(image, channels=3)\n",
        "    image = tf.image.resize(image, IMG_SIZE)\n",
        "    return image\n",
        "\n",
        "def create_dataset(df, image_dir, level):\n",
        "    \"\"\"Create TensorFlow dataset from file paths.\"\"\"\n",
        "    filepaths = [os.path.join(image_dir, fname) for fname in df[\"filename\"]]\n",
        "    df, _ = encode_labels(df, level)\n",
        "    labels = df[level].values  # Ensure labels are properly encoded\n",
        "\n",
        "\n",
        "\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((filepaths, labels))\n",
        "    dataset = dataset.map(lambda x, y: (preprocess_image(x), y), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    dataset = dataset.batch(128).prefetch(tf.data.AUTOTUNE)\n",
        "    return dataset\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Z5Vg4kep084P"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = create_stratified_dataset(data_splits[\"subclass\"][0], \"/content/drive/MyDrive/IMAGES_final\", \"subclass\")\n",
        "test_dataset = create_dataset(data_splits[\"subclass\"][1], \"/content/drive/MyDrive/IMAGES_final\", \"subclass\")"
      ],
      "metadata": {
        "id": "Mzk6ZPc7wgbO"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = train_dataset.map(\n",
        "    lambda x, y: (tf.cast(x, tf.uint8), tf.cast(y, tf.int64))\n",
        ")\n",
        "\n",
        "test_dataset = test_dataset.map(\n",
        "    lambda x, y: (tf.cast(x, tf.uint8), tf.cast(y, tf.int64))\n",
        ")\n"
      ],
      "metadata": {
        "id": "Qw14Q9t2yh2C"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I_YPD73W70Hw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import collections\n",
        "\n",
        "# Extract labels efficiently without converting dataset to NumPy\n",
        "def extract_labels(dataset):\n",
        "    all_labels = []\n",
        "    for _, labels in dataset:  # ✅ Avoids unnecessary NumPy conversion\n",
        "        all_labels.append(labels)  # ✅ Collects tensor labels efficiently\n",
        "\n",
        "    return tf.concat(all_labels, axis=0).numpy()  # ✅ Convert only once at the end\n",
        "\n",
        "# 🚀 Efficient Label Extraction (No NumPy Overhead)\n",
        "all_labels = extract_labels(train_dataset)\n",
        "\n",
        "# Count occurrences\n",
        "label_counts_after = collections.Counter(all_labels)\n",
        "\n",
        "# Print label distribution\n",
        "print(\"\\nNumber of samples per label AFTER adding noise:\\n\")\n",
        "for label, count in sorted(label_counts_after.items()):\n",
        "    print(f\"Label {label}: {count} samples\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7z0suDdYyaM0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print shape of the first batch\n",
        "for batch_images, batch_labels in train_dataset.take(1):\n",
        "    print(f\"Train Dataset - Batch Images Shape: {batch_images.shape}\")\n",
        "    print(f\"Train Dataset - Batch Labels Shape: {batch_labels.shape}\")\n",
        "\n",
        "for batch_images, batch_labels in test_dataset.take(1):\n",
        "    print(f\"Test Dataset - Batch Images Shape: {batch_images.shape}\")\n",
        "    print(f\"Test Dataset - Batch Labels Shape: {batch_labels.shape}\")\n",
        "\n",
        "\n",
        "# Print the datatype of the first batch\n",
        "for batch_images, batch_labels in train_dataset.take(1):\n",
        "    print(f\"Train Dataset - Batch Images dtype: {batch_images.dtype}\")\n",
        "    print(f\"Train Dataset - Batch Labels dtype: {batch_labels.dtype}\")\n",
        "\n",
        "for batch_images, batch_labels in test_dataset.take(1):\n",
        "    print(f\"Test Dataset - Batch Images dtype: {batch_images.dtype}\")\n",
        "    print(f\"Test Dataset - Batch Labels dtype: {batch_labels.dtype}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "5eluaLhrCpqd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DvMhx1rtr28z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_feature_extraction_model(shape=(224, 224, 3), summary=True):\n",
        "    \"\"\"Builds a ConvNeXtTiny feature extractor with a fixed input shape.\"\"\"\n",
        "\n",
        "    inputs = tf.keras.layers.Input(shape=shape)\n",
        "    x = augmentation_model(inputs)\n",
        "\n",
        "    pre_trained_model = tf.keras.applications.ConvNeXtTiny(\n",
        "\n",
        "      include_top=False,\n",
        "      weights='imagenet',\n",
        "      input_shape=shape,\n",
        "      pooling=None\n",
        "    )\n",
        "    x = pre_trained_model(x)\n",
        "    x = tf.keras.layers.GlobalMaxPooling2D()(x)\n",
        "\n",
        "    feature_extraction_model = tf.keras.Model(inputs=inputs, outputs=x)\n",
        "\n",
        "    # Freeze pre-trained model\n",
        "    pre_trained_model.trainable = False\n",
        "    if summary:\n",
        "        print(feature_extraction_model.summary())\n",
        "\n",
        "\n",
        "    return feature_extraction_model\n",
        "\n"
      ],
      "metadata": {
        "id": "7K7vE4WUr7Uu"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_SHAPE = IMG_SIZE + (3,)\n",
        "feature_extraction_model = build_feature_extraction_model(INPUT_SHAPE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 378
        },
        "id": "mdgr1xZJr8PF",
        "outputId": "2acd6baf-aede-4011-831f-e4ffa2eecbb6"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/convnext/convnext_tiny_notop.h5\n",
            "\u001b[1m111650432/111650432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_5\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_5\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ sequential (\u001b[38;5;33mSequential\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ convnext_tiny (\u001b[38;5;33mFunctional\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m768\u001b[0m)           │      \u001b[38;5;34m27,820,128\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_max_pooling2d                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalMaxPooling2D\u001b[0m)                 │                             │                 │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ sequential (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ convnext_tiny (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)           │      <span style=\"color: #00af00; text-decoration-color: #00af00\">27,820,128</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_max_pooling2d                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling2D</span>)                 │                             │                 │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m27,820,128\u001b[0m (106.13 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">27,820,128</span> (106.13 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m27,820,128\u001b[0m (106.13 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">27,820,128</span> (106.13 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def batched_feature_extraction(model, image_batch):\n",
        "    # Single forward pass with training=True\n",
        "    return model(image_batch, training=True)\n",
        "\n",
        "def extract_features_in_batches(model, dataset, repetitions=1):\n",
        "    X, Y = [], []\n",
        "    for i in range(repetitions):\n",
        "        if i:\n",
        "            print(\"\\nRepetition\", i)\n",
        "        for batch_idx, (image_batch, label_batch) in enumerate(dataset):\n",
        "            Y.extend(label_batch)\n",
        "            # Single call that can be retraced once if shapes/dtypes are stable\n",
        "            features = batched_feature_extraction(model, image_batch)\n",
        "            X.extend(features)\n",
        "    return np.array(X), np.array(Y)\n"
      ],
      "metadata": {
        "id": "pGpASKCKvpi4"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_features_with_predict(model, dataset):\n",
        "    # Keras handles batching automatically in a single pass\n",
        "    X = model.predict(dataset, verbose=1)\n",
        "    # Gather labels\n",
        "    Y_list = []\n",
        "    for _, labels in dataset:\n",
        "        Y_list.append(labels)\n",
        "    Y = tf.concat(Y_list, axis=0)\n",
        "    return X, Y.numpy()\n"
      ],
      "metadata": {
        "id": "lsaohNyzsGMX"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Wp3uYNWFF2Io"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### START YOUR CODE HERE ###  (≈2 LOC)\n",
        "\n",
        "# Training features and labels\n",
        "train_features, train_labels = extract_features_in_batches(feature_extraction_model, train_dataset)\n",
        "\n",
        "# Test features and labels\n",
        "test_features, test_labels = extract_features_with_predict(feature_extraction_model, test_dataset)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rdKnH3gS4ffF",
        "outputId": "623de08a-2ee4-4a16-8b29-fb6e6c9b160f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m257s\u001b[0m 2s/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Shape of train_features:\", train_features.shape)\n",
        "print(\"Number of samples:\", len(train_features))\n",
        "\n",
        "print(\"Shape of train_features:\", test_features.shape)\n",
        "print(\"Number of samples:\", len(test_features))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LbVqe57dk34X",
        "outputId": "1d113526-4e5e-463c-d9ec-702ab31206a4"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of train_features: (58368, 768)\n",
            "Number of samples: 58368\n",
            "Shape of train_features: (14378, 768)\n",
            "Number of samples: 14378\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf.fit(train_features, train_labels)\n",
        "\n",
        "predictions = rf.predict(test_features)\n",
        "accuracy = accuracy_score(test_labels, predictions)\n",
        "\n",
        "print(f\"Test Accuracy: {accuracy}\")\n",
        "print(classification_report(test_labels, predictions))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjyOqG7d4EOO",
        "outputId": "514f0559-e28a-4de2-8a28-f6b1f08c25f6"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.6859785783836416\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       521\n",
            "           1       0.50      0.01      0.02       589\n",
            "           2       0.64      0.87      0.74      6771\n",
            "           3       0.00      0.00      0.00        13\n",
            "           4       0.00      0.00      0.00       655\n",
            "           5       0.76      0.68      0.72      5829\n",
            "\n",
            "    accuracy                           0.69     14378\n",
            "   macro avg       0.32      0.26      0.25     14378\n",
            "weighted avg       0.63      0.69      0.64     14378\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -- A) Weighted Random Forest -----------------------------------------------\n",
        "print(\"\\n=== Weighted Random Forest ===\")\n",
        "rf_weighted = RandomForestClassifier(\n",
        "    n_estimators=100,\n",
        "    random_state=42,\n",
        "    class_weight='balanced'  # <-- Important for imbalance\n",
        ")\n",
        "rf_weighted.fit(train_features, train_labels)\n",
        "\n",
        "predictions_weighted = rf_weighted.predict(test_features)\n",
        "accuracy_weighted = accuracy_score(test_labels, predictions_weighted)\n",
        "\n",
        "print(f\"Weighted RF Test Accuracy: {accuracy_weighted}\")\n",
        "print(classification_report(test_labels, predictions_weighted))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rqUkGzuQzpaE",
        "outputId": "65093210-e5ec-4b00-9c28-c75bda422806"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Weighted Random Forest ===\n",
            "Weighted RF Test Accuracy: 0.6601057170677423\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       521\n",
            "           1       1.00      0.00      0.01       589\n",
            "           2       0.61      0.88      0.72      6771\n",
            "           3       0.00      0.00      0.00        13\n",
            "           4       0.00      0.00      0.00       655\n",
            "           5       0.76      0.61      0.68      5829\n",
            "\n",
            "    accuracy                           0.66     14378\n",
            "   macro avg       0.40      0.25      0.23     14378\n",
            "weighted avg       0.64      0.66      0.61     14378\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -- B) Balanced Bagging Classifier ------------------------------------------\n",
        "print(\"\\n=== BalancedBaggingClassifier (with RF base) ===\")\n",
        "from imblearn.ensemble import BalancedBaggingClassifier\n",
        "bbc = BalancedBaggingClassifier(\n",
        "    estimator=RandomForestClassifier(n_estimators=100, random_state=42),\n",
        "    n_estimators=10,\n",
        "    random_state=42\n",
        ")\n",
        "bbc.fit(train_features, train_labels)\n",
        "\n",
        "predictions_bbc = bbc.predict(test_features)\n",
        "accuracy_bbc = accuracy_score(test_labels, predictions_bbc)\n",
        "\n",
        "print(f\"BalancedBaggingClassifier Test Accuracy: {accuracy_bbc}\")\n",
        "print(classification_report(test_labels, predictions_bbc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZfWf9JFzs0k",
        "outputId": "982b7153-99d9-4e55-a5f9-59eee1520f65"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== BalancedBaggingClassifier (with RF base) ===\n",
            "BalancedBaggingClassifier Test Accuracy: 0.3809987480873557\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.24      0.46      0.32       521\n",
            "           1       0.07      0.60      0.13       589\n",
            "           2       0.74      0.41      0.53      6771\n",
            "           3       0.01      0.77      0.02        13\n",
            "           4       0.17      0.24      0.20       655\n",
            "           5       0.75      0.33      0.46      5829\n",
            "\n",
            "    accuracy                           0.38     14378\n",
            "   macro avg       0.33      0.47      0.28     14378\n",
            "weighted avg       0.67      0.38      0.46     14378\n",
            "\n"
          ]
        }
      ]
    }
  ]
}